{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import spacy\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "suffixes = list(nlp.Defaults.suffixes)\n",
    "suffixes.remove(\"#\")\n",
    "suffix_regex = spacy.util.compile_suffix_regex(suffixes)\n",
    "nlp.tokenizer.suffix_search = suffix_regex.search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Echantillonage Train/Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open(\"Data/X.pickle\", \"rb\"))\n",
    "y = pickle.load(open(\"Data/y.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:20000]\n",
    "X_test = X[20000:]\n",
    "\n",
    "y_train = y[:20000]\n",
    "y_test = y[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- **Nettoyage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fonction Nettoyage**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va faire une fonction à base de regex qui enlèvera les chiffres, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(texte):\n",
    "    \n",
    "    char_gardes = r'[^a-z#+.\\s]'\n",
    "    return re.sub(char_gardes, '', texte)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fonction stopWords + Verbes + Space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suppression des stopwords n'est pas systématique en NLP. Mais dans notre cas, où on travaille sur l'extraction de thème, ça l'est."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sw(texte, return_verbs, return_token):\n",
    "    \n",
    "    doc = nlp(texte)\n",
    "    \n",
    "    if return_verbs :\n",
    "    \n",
    "        tokens = [token for token in doc if \\\n",
    "                  token.is_stop == False and token.is_punct == False\\\n",
    "                  and token.is_space == False\n",
    "                 ]\n",
    "    \n",
    "    else :\n",
    "        \n",
    "        tokens = [token for token in doc if \\\n",
    "                  token.is_stop == False and token.is_punct == False\\\n",
    "                  and token.pos_ != \"VERB\"\\\n",
    "                  and token.is_space == False\n",
    "                 ]\n",
    "    \n",
    "    if return_token :\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    txt = \"\"\n",
    "    \n",
    "    for t in tokens :\n",
    "        \n",
    "        txt = txt + \" \" + t.text\n",
    "        txt = txt.lstrip()\n",
    "        \n",
    "    return txt\n",
    "\n",
    "\n",
    "def pipe_clsw(texte, return_verbs = True, return_token = True):\n",
    "    \"\"\"\n",
    "    Nettoye et enlève les SW d'un text/str et retourne une liste de tokens.\n",
    "    Par défaut : \n",
    "    - On garde les verbe. Si False on les élimine du résultat.\n",
    "    - On retourne une liste de token. Si False on retourne une str des tokens.\n",
    "    \"\"\"\n",
    "    \n",
    "    res = remove_sw(clean_text(texte), return_verbs, return_token)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"flutter animated container i have a raisedbutton widget and an animatedcontainer widget in a screen, and the idea is that upon pressing the raisedbutton the width of the animatedcontainer would then decrease in a given duration. the documentation of the animatedcontainer states that all i would need to do is declare the width of the widget as a variable, and then setstate(() {}) after changing the value and it will automatically change to that value during the duration. i have tried to implement this and upon pressing the raisedbutton the variables value definitely changes (based on printing the value of it after pressing it), however the widget's width does not change with it. am i missing something obvious? my widgets are within a container in a pageview and my code for the raisedbutton and animatedcontainer is as follows: here is my widget tree:\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[flutter, animated, container, raisedbutton, widget, animatedcontainer, widget, screen, idea, pressing, raisedbutton, width, animatedcontainer, decrease, given, duration, documentation, animatedcontainer, states, need, declare, width, widget, variable, setstate, changing, value, automatically, change, value, duration, tried, implement, pressing, raisedbutton, variables, value, definitely, changes, based, printing, value, pressing, widgets, width, change, missing, obvious, widgets, container, pageview, code, raisedbutton, animatedcontainer, follows, widget, tree]\n"
     ]
    }
   ],
   "source": [
    "res = pipe_clsw(X_train[250])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'flutter container raisedbutton widget animatedcontainer widget screen idea raisedbutton width animatedcontainer duration documentation animatedcontainer width widget variable setstate value automatically value duration raisedbutton variables value definitely changes value widgets width obvious widgets container pageview code raisedbutton animatedcontainer widget tree'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pipe_clsw(X_train[250], False, False)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Approche non-supervisée**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LDA - Count**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Texte sans verbes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['script inside aws lambda function bash script inside lambda function aws docs code python nodejs java documents possible bash concrete evidence example',\n",
       " 'boot controller content negotiation simple rest controller springboot application sure content negotiation json xml contenttype parameter request header wrong controller method json method contenttype applicationxml textxml methods different mapping different content type able xml xml mediatypes single method like example message endpoint xml contenttype request applicationxmljson contenttype applicationjson help editi controller media types',\n",
       " 'error goto statement vba code particular value excel sheet ctrl+f command code message problem error message message box error']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean = [pipe_clsw(t, False, False) for t in X_train]\n",
    "X_train_clean[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"Data/dat_clean_text_no_verbs.pickle\", \"wb\")\n",
    "pickle.dump(X_train_clean, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = pickle.load(open(\"Data/dat_clean_text_no_verbs.pickle\", \"rb\"))\n",
    "\n",
    "# HP du nombre de sujets : 31 pour les 30 suejts représentés par les tags + 1 \"misc\"\n",
    "nb_sujets = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(max_df=0.95, min_df=4,\n",
       "                tokenizer=<function neutral_tokenizer at 0x0000000014AAE9D0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bypass tokenizer à cause de node.js on veut une separation que sur les espace, ce qui permet de conserver des\n",
    "# expressions contenant des points qui nous paraiossent importantes...\n",
    "\n",
    "def neutral_tokenizer(tokens):\n",
    "    \n",
    "    return tokens.split(\" \")\n",
    "\n",
    "tf_vect = CountVectorizer(max_df = 0.95, min_df = 4, tokenizer = neutral_tokenizer)\n",
    "tf_vect.fit(X_train_clean)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# on utilise le \"custom tokenizer ci-dessus...\n",
    "tf_vect = CountVectorizer(max_df = 0.95, min_df = 4)\n",
    "tf_vect.fit(X_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 6722)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean_vect = tf_vect.transform(X_train_clean)\n",
    "X_train_clean_vect.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_tf = LatentDirichletAllocation(n_components = nb_sujets, \n",
    "                                max_iter = 5,\n",
    "                                learning_method = \"online\",\n",
    "                                learning_offset = 50., \n",
    "                                random_state = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'entrainement de la LDA a mis : 30.283731937408447 secondes.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "lda_tf.fit(X_train_clean_vect)\n",
    "print(f\"L'entrainement de la LDA a mis : {time() - start} secondes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montrer_sujets(model, feature_names, nb_top_words) :\n",
    "    \n",
    "    for sujet_idx, sujet in enumerate(model.components_):\n",
    "        print(f\"topic numéro {sujet_idx} :\")\n",
    "        print(\" \".join(feature_names[i] for i in sujet.argsort()[: -nb_top_words -1:-1]))\n",
    "        print(\"----------------------------------\")\n",
    "        \n",
    "def retourne_tags(model, feature_names) :\n",
    "    \n",
    "    liste = []\n",
    "    \n",
    "    for sujet_idx, sujet in enumerate(model.components_):\n",
    "        # print(f\"topic numéro {sujet_idx} :\")\n",
    "        \n",
    "        liste.append(feature_names[sujet.argmax()])\n",
    "        \n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic numéro 0 :\n",
      "api request server service url error response chrome web http\n",
      "----------------------------------\n",
      "topic numéro 1 :\n",
      "function query loop functions code aws promise boolean n inside\n",
      "----------------------------------\n",
      "topic numéro 2 :\n",
      "devtools dag airflow encryption soap wcf bitmap clang fire concurrent\n",
      "----------------------------------\n",
      "topic numéro 3 :\n",
      "error object class nt method code string like property new\n",
      "----------------------------------\n",
      "topic numéro 4 :\n",
      "array number y x size item items numpy c memory\n",
      "----------------------------------\n",
      "topic numéro 5 :\n",
      "version studio visual nt code + database mysql way question\n",
      "----------------------------------\n",
      "topic numéro 6 :\n",
      "angular component element components event template parent page like child\n",
      "----------------------------------\n",
      "topic numéro 7 :\n",
      "npm start node v node.js module package.json error cli ng\n",
      "----------------------------------\n",
      "topic numéro 8 :\n",
      "column dataframe pandas data columns values row rows csv like\n",
      "----------------------------------\n",
      "topic numéro 9 :\n",
      "react google state native cloud const action store graph hook\n",
      "----------------------------------\n",
      "topic numéro 10 :\n",
      "db testing desktop usage h ms express li ambient mongo\n",
      "----------------------------------\n",
      "topic numéro 11 :\n",
      "user password option login webpack users account public new messages\n",
      "----------------------------------\n",
      "topic numéro 12 :\n",
      "view swift field custom index conda cell navigation programmatically swiftui\n",
      "----------------------------------\n",
      "topic numéro 13 :\n",
      "file button text code html nt form bootstrap like css\n",
      "----------------------------------\n",
      "topic numéro 14 :\n",
      "image docker container images nt like default way inside host\n",
      "----------------------------------\n",
      "topic numéro 15 :\n",
      "data json type content parameter parameters types checkbox validation query\n",
      "----------------------------------\n",
      "topic numéro 16 :\n",
      "table page core controller .net script asp.net framework laravel sql\n",
      "----------------------------------\n",
      "topic numéro 17 :\n",
      "git environment variable local repository github variables branch remote changes\n",
      "----------------------------------\n",
      "topic numéro 18 :\n",
      "block release.jar symbol pointer markdown catch viewmodel void springbeans clickable\n",
      "----------------------------------\n",
      "topic numéro 19 :\n",
      "package packages notebook jupyter r export prompt collection pod kubernetes\n",
      "----------------------------------\n",
      "topic numéro 20 :\n",
      "date time format current certificate ssl fragment datetime recyclerview code\n",
      "----------------------------------\n",
      "topic numéro 21 :\n",
      "consumer queue ivy breakpoint breakpoints reducer recycler sqs producer clues\n",
      "----------------------------------\n",
      "topic numéro 22 :\n",
      "difference vs open oracle vscode schema regular alert queries th\n",
      "----------------------------------\n",
      "topic numéro 23 :\n",
      "test spring application exception boot context configuration true c++ tests\n",
      "----------------------------------\n",
      "topic numéro 24 :\n",
      "div height width color px icon xml size layout plot\n",
      "----------------------------------\n",
      "topic numéro 25 :\n",
      "attribute box network kotlin dialog cookie attributeerror vm cookies plain\n",
      "----------------------------------\n",
      "topic numéro 26 :\n",
      "python module pip import key model tensorflow anaconda version nt\n",
      "----------------------------------\n",
      "topic numéro 27 :\n",
      "value list input nt way values like code multiple example\n",
      "----------------------------------\n",
      "topic numéro 28 :\n",
      "project java version library gradle error build warning file plugin\n",
      "----------------------------------\n",
      "topic numéro 29 :\n",
      "android app studio ios xcode error device screen flutter nt\n",
      "----------------------------------\n",
      "topic numéro 30 :\n",
      "error file command nt windows code message line folder path\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# countvect token par defaut\n",
    "montrer_sujets(lda_tf, tf_vect.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction de la liste des meilleurs mots pouvant servir de tags..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['api', 'function', 'devtools', 'error', 'array', 'version', 'angular', 'npm', 'column', 'react', 'db', 'user', 'view', 'file', 'image', 'data', 'table', 'git', 'block', 'package', 'date', 'consumer', 'difference', 'test', 'div', 'attribute', 'python', 'value', 'project', 'android', 'error']\n"
     ]
    }
   ],
   "source": [
    "liste_tags_lda_tf = retourne_tags(lda_tf, tf_vect.get_feature_names())\n",
    "print(liste_tags_lda_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 31)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score_tf = lda_tf.transform(X_train_clean_vect)\n",
    "topic_score_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00140252, 0.59202265, 0.00140252, 0.00140252, 0.00140252,\n",
       "       0.00140252, 0.00140252, 0.04488078, 0.00140252, 0.00140252,\n",
       "       0.00140252, 0.00140252, 0.00140252, 0.00140252, 0.00140252,\n",
       "       0.00140252, 0.08904097, 0.08943088, 0.00140252, 0.00140252,\n",
       "       0.00140252, 0.00140252, 0.00140252, 0.00140252, 0.00140252,\n",
       "       0.00140252, 0.04804115, 0.05761499, 0.04530798, 0.00140252,\n",
       "       0.00140252])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score_tf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 15, 30, ...,  3, 14, 30], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_predicted_tf = np.argmax(topic_score_tf, axis = 1)\n",
    "\n",
    "# sauvegarde\n",
    "pickle_out = open(\"Data/topic_predicted_tf.pickle\", \"wb\")\n",
    "pickle.dump(topic_predicted_tf, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "topic_predicted_tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA a prédit des topics et a assigné les questions à ces topics... Mais comment en tire-t-on des tags pour nos question ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Approche totalement non-supervisée**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette approche consisterait à récupérer les 1ers termes du model pour chaque topic et à les choisir pour tags correspondant à ce topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour évaluer les résultats qu'on pourrait obtenir par cette approche au regard des tags à prévoir il faut regarder deux choses :<br>- Les tags eux-mêmes.<br>- Le nombre de tags par question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparaison tags originaux, tags LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['api', 'function', 'devtools', 'error', 'array', 'version', 'angular', 'npm', 'column', 'react', 'db', 'user', 'view', 'file', 'image', 'data', 'table', 'git', 'block', 'package', 'date', 'consumer', 'difference', 'test', 'div', 'attribute', 'python', 'value', 'project', 'android', 'error']\n"
     ]
    }
   ],
   "source": [
    "print(liste_tags_lda_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['android', 'angular', 'asp.net', 'c#', 'code', 'css', 'docker', 'flutter', 'git', 'google', 'html', 'ios', 'java', 'javascript', 'jquery', 'json', 'laravel', 'misc', 'mysql', 'node.js', 'pandas', 'php', 'python', 'react', 'spring', 'sql', 'swift', 'typescript', 'visual', 'web', 'windows']\n"
     ]
    }
   ],
   "source": [
    "vect_y = CountVectorizer(tokenizer = neutral_tokenizer).fit(y_train)\n",
    "liste_tags_reels = vect_y.get_feature_names()\n",
    "print(liste_tags_reels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eléments communs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['react', 'android', 'git', 'python', 'angular'] 5\n"
     ]
    }
   ],
   "source": [
    "common = list(set(liste_tags_lda_tf).intersection(liste_tags_reels))\n",
    "print(common, len(common))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il n'y a que 5 tags en commun, ce qui jette de sérieux doute sur la pertinence de notre démarche..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Nombre de tags par question**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La façon la plus pertinente de soutirer plusieurs tags à notre modèle LDA serait de passer par une logique de seuil. On peut donc regarder s'il y a un rapport éventuel entre le nombre de tags à prévoir pour chaque question et les topics score prédit par le modèle LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 1, 2, 1, 1, 1, 2, 1, 2]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste du nombre de tags à prédire de y_train\n",
    "len_y = []\n",
    "\n",
    "for s in y_train :\n",
    "    len_y.append(len(s.split()))\n",
    "    \n",
    "len_y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons à quels **topic score** correspondent les n-ièmes tags cibles pour chaque question (pour les 10 première questions...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5920226517034007\n",
      "0.2153120613717825\n",
      "0.7447321786377393\n",
      "0.3815435970685162\n",
      "0.4659271432855029\n",
      "0.7670075957299393\n",
      "0.4534244923828475\n",
      "0.06881730731637903\n",
      "0.3007856542725834\n",
      "0.26145307184557964\n"
     ]
    }
   ],
   "source": [
    "seuils_topic_score = []\n",
    "\n",
    "for i, n in zip(topic_score_tf[:10], len_y[:10]) :\n",
    "    ar = np.sort(i)\n",
    "    print(ar[-n])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rehardons si ces valeurs pourrait se déduire d'une condition type \"être au dessus d'un certain seuil\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08943087847676548\n",
      "0.19542571477915335\n",
      "0.09698229220278344\n",
      "0.1356607296680963\n",
      "0.22420731721295192\n",
      "0.09238593551882536\n",
      "0.3712734850698988\n",
      "0.002150537634410425\n",
      "0.21620325705915075\n",
      "0.0933930027653001\n"
     ]
    }
   ],
   "source": [
    "for i, n in zip(topic_score_tf[:10], len_y[:10]) :\n",
    "    ar = np.sort(i)\n",
    "    print(ar[-(n+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble impossible de définir un seuil de \"topic score\" à partir duquel tagger une question permettant de faire correspondre un nombre de tags issus du modèle LDA avec le nombre de tags cibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les tags déduits du modèles LDA sont différents des tags cibles.<br>Il semble de plus difficile de trouver une logique permettant de faire matcher un nombre de tags par question issu du modèle LDA avec les nombres de tags par question de la cible.<br><br>Ce **manque d'éléments communs** rend **impossible** une **évaluation sérieuse** du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'utilisation de modèle LDA est adaptée à la recherche thématique dans un cadre vierge, mais n'est pas pertinente ici, dans un cadre sémantique déjà fixé, qui rend hasardeux l'attribution de tag par des méthodes statistiques non supervisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Approche LDA - TFIDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour voir par exemple si avec une telle approche on trouverait plus de tags présents dans la liste cible..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = pickle.load(open(\"Data/dat_clean_text_no_verbs.pickle\", \"rb\"))\n",
    "nb_sujets = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.95, min_df=5)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def neutral_tokenizer(tokens):\n",
    "    \n",
    "    return tokens.split(\" \")\n",
    "\n",
    "#idf_vect = TfidfVectorizer(tokenizer = neutral_tokenizer, token_pattern = r'(?u)\\b\\w\\w+__.\\([\\w\\s]*\\)')\n",
    "#tokpat = r'([^a-z#+.\\s]{2,})'\n",
    "token_pattern = tokpat\n",
    "idf_vect = TfidfVectorizer(max_df = 0.95, min_df = 5)\n",
    "\n",
    "idf_vect.fit(X_train_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 5777)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean_idf = idf_vect.transform(X_train_clean)\n",
    "X_train_clean_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_idf = LatentDirichletAllocation(n_components = nb_sujets, \n",
    "                                max_iter = 5,\n",
    "                                learning_method = \"online\",\n",
    "                                learning_offset = 50., \n",
    "                                random_state = 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'entrainement de la LDA_idf a mis : 21.74224352836609 secondes.\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "lda_idf.fit(X_train_clean_idf)\n",
    "print(f\"L'entrainement de la LDA_idf a mis : {time() - start} secondes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic numéro 0 :\n",
      "date format datetime modal timezone yyyymmdd instagram ddmmyyyy epoch mmddyyyy\n",
      "----------------------------------\n",
      "topic numéro 1 :\n",
      "code error nt angular like function data value component array\n",
      "----------------------------------\n",
      "topic numéro 2 :\n",
      "certificate ssl tls gulp nodejs curl websocket pgadmin ip openssl\n",
      "----------------------------------\n",
      "topic numéro 3 :\n",
      "color background px white svg theme black button textinputlayout cat\n",
      "----------------------------------\n",
      "topic numéro 4 :\n",
      "uuid oracle schema arrays ubuntu equal commands contents api open\n",
      "----------------------------------\n",
      "topic numéro 5 :\n",
      "ngoninit async asyncawait babel promise obviously scratch await babelrc angular\n",
      "----------------------------------\n",
      "topic numéro 6 :\n",
      "tensorflow tf cuda gpu placeholder cpu uitextfield duration startdate tensorflowgpu\n",
      "----------------------------------\n",
      "topic numéro 7 :\n",
      "markdown ivy gif other textual esm commonjs symbol es standards\n",
      "----------------------------------\n",
      "topic numéro 8 :\n",
      "docker container dockerfile dockercompose image flask containers yml nginx host\n",
      "----------------------------------\n",
      "topic numéro 9 :\n",
      "folder public conda images environment machine structure reactjs network webpack\n",
      "----------------------------------\n",
      "topic numéro 10 :\n",
      "jupyter notebook ipython ruby phone electron kernel prettier tr td\n",
      "----------------------------------\n",
      "topic numéro 11 :\n",
      "kubernetes pod pods kubectl cluster favicon city nodes ico namespace\n",
      "----------------------------------\n",
      "topic numéro 12 :\n",
      "jenkins pipeline notification channel groovy notifications job push fcm whatsapp\n",
      "----------------------------------\n",
      "topic numéro 13 :\n",
      "ubuntu numpy ansible importerror module javafx aptget python alpine virtualbox\n",
      "----------------------------------\n",
      "topic numéro 14 :\n",
      "firestore camera yaml tabs audio ffmpeg tablayout stream shadow constraintlayout\n",
      "----------------------------------\n",
      "topic numéro 15 :\n",
      "tid workbench client webcam bits dockers props literal installers sockets\n",
      "----------------------------------\n",
      "topic numéro 16 :\n",
      "order max virtualbox query date mistake year somebody years docker\n",
      "----------------------------------\n",
      "topic numéro 17 :\n",
      "python pip anaconda conda opencv environment version packages package py\n",
      "----------------------------------\n",
      "topic numéro 18 :\n",
      "android gradle flutter studio build error app project emulator apk\n",
      "----------------------------------\n",
      "topic numéro 19 :\n",
      "icon toolbar icons design menu appcompatactivity material fontawesome awesome jasmine\n",
      "----------------------------------\n",
      "topic numéro 20 :\n",
      "swift view swiftui cell programmatically textfield label scroll storyboard viewpager\n",
      "----------------------------------\n",
      "topic numéro 21 :\n",
      "signalr xsd orgmaven fromto orgpom orgxsdmaven xsischemalocationhttpmaven threading net nuget\n",
      "----------------------------------\n",
      "topic numéro 22 :\n",
      "git branch repository github master commit remote repo fatal branches\n",
      "----------------------------------\n",
      "topic numéro 23 :\n",
      "xcode ios swift beta iphone apple simulator device macos cocoapods\n",
      "----------------------------------\n",
      "topic numéro 24 :\n",
      "latex variance readme atlassian github ssh markdown md intellij pub\n",
      "----------------------------------\n",
      "topic numéro 25 :\n",
      "appreciable volley unexpected response code request android links network wrong\n",
      "----------------------------------\n",
      "topic numéro 26 :\n",
      "checkbox selenium recaptcha radio disabled validate checkboxes firefox xpath unchecked\n",
      "----------------------------------\n",
      "topic numéro 27 :\n",
      "product positional cart woocommerce multiplication jinja forloop fromjson iloc iteration\n",
      "----------------------------------\n",
      "topic numéro 28 :\n",
      "error file nt code project server version app command java\n",
      "----------------------------------\n",
      "topic numéro 29 :\n",
      "django py pdf colab boto manage blob xlsx python migrate\n",
      "----------------------------------\n",
      "topic numéro 30 :\n",
      "bytecode surefire componentwillreceiveprops jvm react styling url target inline refactor\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "montrer_sujets(lda_idf, idf_vect.get_feature_names(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 31)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score_idf = lda_idf.transform(X_train_clean_idf)\n",
    "topic_score_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ...,  1, 28, 28], dtype=int64)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_predicted_idf = np.argmax(topic_score_idf, axis = 1)\n",
    "topic_predicted_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00813409, 0.72688735, 0.00813409, 0.00813409, 0.00813409,\n",
       "       0.00813409, 0.00813409, 0.00813409, 0.00813409, 0.00813409,\n",
       "       0.00813409, 0.00813409, 0.00813409, 0.03722393, 0.00813409,\n",
       "       0.00813409, 0.00813409, 0.00813409, 0.00813409, 0.00813409,\n",
       "       0.00813409, 0.00813409, 0.00813409, 0.00813409, 0.00813409,\n",
       "       0.00813409, 0.00813409, 0.00813409, 0.00813409, 0.00813409,\n",
       "       0.00813409])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score_idf[150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['date', 'code', 'certificate', 'color', 'uuid', 'ngoninit', 'tensorflow', 'markdown', 'docker', 'folder', 'jupyter', 'kubernetes', 'jenkins', 'ubuntu', 'firestore', 'tid', 'order', 'python', 'android', 'icon', 'swift', 'signalr', 'git', 'xcode', 'latex', 'appreciable', 'checkbox', 'product', 'error', 'django', 'bytecode']\n"
     ]
    }
   ],
   "source": [
    "liste_tags_lda_idf = retourne_tags(lda_idf, idf_vect.get_feature_names())\n",
    "print(liste_tags_lda_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['android', 'angular', 'asp.net', 'c#', 'code', 'css', 'docker', 'flutter', 'git', 'google', 'html', 'ios', 'java', 'javascript', 'jquery', 'json', 'laravel', 'misc', 'mysql', 'node.js', 'pandas', 'php', 'python', 'react', 'spring', 'sql', 'swift', 'typescript', 'visual', 'web', 'windows']\n"
     ]
    }
   ],
   "source": [
    "print(liste_tags_reels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['android', 'git', 'python', 'swift', 'code', 'docker'] 6\n"
     ]
    }
   ],
   "source": [
    "common_idf = list(set(liste_tags_lda_idf).intersection(liste_tags_reels))\n",
    "print(common_idf, len(common_idf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 terme en communs, c'est un peu mieux que l'approche **CountVectorizer**, mais rien de transcendant... On ne pousse pas plus loin, on reste sur la même conclusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 31)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_score_idf = lda_idf.transform(X_train_clean_idf)\n",
    "topic_score_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ...,  1, 28, 28], dtype=int64)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_predicted_idf = np.argmax(topic_score_idf, axis = 1)\n",
    "\n",
    "# sauvegarde\n",
    "pickle_out = open(\"Data/topic_predicted_idf.pickle\", \"wb\")\n",
    "pickle.dump(topic_predicted_idf, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "topic_predicted_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28, 28, 28,  1,  1, 28, 28,  1, 28, 28,  1, 28, 17,  1, 28, 28,  1,\n",
       "       28,  1, 28, 28, 28,  1, 28, 28,  1, 28, 28,  1, 28,  1,  0, 28, 28,\n",
       "       28, 12,  1, 28, 28, 28, 28,  1, 28, 28, 28,  1, 28,  1,  3, 28,  1,\n",
       "        1,  1, 28,  1,  1,  1,  0, 28,  1, 28,  1, 28,  1,  1, 28,  1,  1,\n",
       "       28,  1,  1,  1, 28,  1,  1,  1,  1, 28,  1,  1, 28,  1, 18,  1,  1,\n",
       "        1, 18,  1, 28,  1,  1,  1, 12, 28, 28, 28,  1, 28, 28, 28],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_predicted_idf[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     10317\n",
       "28     8629\n",
       "18      390\n",
       "17      141\n",
       "8        88\n",
       "22       83\n",
       "23       65\n",
       "13       49\n",
       "20       41\n",
       "0        30\n",
       "3        28\n",
       "6        23\n",
       "29       20\n",
       "14       17\n",
       "12       17\n",
       "10       15\n",
       "11       12\n",
       "2        12\n",
       "19        9\n",
       "26        7\n",
       "7         5\n",
       "27        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count_idf = pd.Series(topic_predicted_idf)\n",
    "topic_count_idf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    3530\n",
       "3     2590\n",
       "13    1390\n",
       "29    1359\n",
       "0     1317\n",
       "27    1191\n",
       "6     1146\n",
       "5     1040\n",
       "28     725\n",
       "26     684\n",
       "14     665\n",
       "8      604\n",
       "4      479\n",
       "20     454\n",
       "1      388\n",
       "24     374\n",
       "23     342\n",
       "16     315\n",
       "17     233\n",
       "7      223\n",
       "12     212\n",
       "11     203\n",
       "15     165\n",
       "9      147\n",
       "19     110\n",
       "25      44\n",
       "22      29\n",
       "10      16\n",
       "18      13\n",
       "2        7\n",
       "21       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count_tf = pd.Series(topic_predicted_tf)\n",
    "topic_count_tf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Approche Mixte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La LDA a note chaque question au regard de topics qu'elle a détecté, on pourrait se servir de ces notes attribuées comme features dans une approche supervisée multilabels.<br>Dans ce cadre, la LDA apparait comme une étape supplémentaire de processing, en l'occurence de **réduction dimensionnelle**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par contre, comme il n'est pas question ici que la LDA extraie elle-même les noms des tags, on va reprendre le pre-processing depuis le début (recours à la lemmatization/stemming) + verbe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Approche données actuelles LDA CV / TFODF<br>\n",
    "2- Nouveau processing, verbe + lemma + stemming ++++ lda ++++ CV et TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpClass",
   "language": "python",
   "name": "opclass"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
